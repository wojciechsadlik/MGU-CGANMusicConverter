{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "raw_audio_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wojciechsadlik/MGU-CGANMusicConverter/blob/main/raw_audio_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptxJ4VdA_iXs",
        "outputId": "87f25bd4-2913-4ef4-e0a9-f1a51f88479d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/MGU-CGANMusicConverter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBmoDT1J_0ye",
        "outputId": "513a23c5-bece-4be1-dad8-d7f39d8636b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/MGU-CGANMusicConverter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "metadata": {
        "id": "YRIext58ATbI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(file_list):\n",
        "  def load_into(filename, x, y):\n",
        "    with open(filename, 'rb') as f:\n",
        "      pkl_file = pickle.load(f)\n",
        "      x.append(pkl_file['audio'])\n",
        "      y.append(int(pkl_file['class_id']))\n",
        "\n",
        "  x, y = [], []\n",
        "  for filename in file_list:\n",
        "    load_into(filename, x, y)\n",
        "\n",
        "  return np.array(x), np.array(y)"
      ],
      "metadata": {
        "id": "r18aIWTlA_kt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "ik7ctZiX3LZY",
        "outputId": "15906196-7b1a-4923-82b0-b645a45a57ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cd1e63475733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIR_TRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'**.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d672936dcea3>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mload_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d672936dcea3>\u001b[0m in \u001b[0;36mload_into\u001b[0;34m(filename, x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mload_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mpkl_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "OUTPUT_DIR_TRAIN = './audio_splitting/output/train'\n",
        "OUTPUT_DIR_TEST = './audio_splitting/output/test'\n",
        "num_classes = 10\n",
        "\n",
        "train_files = glob(os.path.join(OUTPUT_DIR_TRAIN, '**.pkl'))\n",
        "x_train, y_train = get_data(train_files)\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "\n",
        "test_files = glob(os.path.join(OUTPUT_DIR_TEST, '**.pkl'))\n",
        "x_test, y_test = get_data(test_files)\n",
        "y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "print('x_train.shape =', x_train.shape)\n",
        "print('y_train.shape =', y_train.shape)\n",
        "print('x_test.shape =', x_test.shape)\n",
        "print('y_test.shape =', y_test.shape)\n",
        "print('x_train.len =', len(x_train))\n",
        "print('y_train.len =', len(y_train))\n",
        "print('x_test.len =', len(x_test))\n",
        "print('y_test.len =', len(y_test))\n",
        "print(y_train[4799])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.pooling import MaxPooling1D\n",
        "from keras.backend import in_top_k\n",
        "from keras.models import Model\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras import regularizers, Input\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers import LeakyReLU, Add\n",
        "\n",
        "AUDIO_LENGTH = 110250\n",
        "\n",
        "def add_Res1D(y, kernel_size, filters, strides=1):\n",
        "  y_shortcut = y\n",
        "\n",
        "  y = Conv1D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(y)\n",
        "  y = BatchNormalization()(y)\n",
        "  y = LeakyReLU()(y)\n",
        "  y = Conv1D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(y)\n",
        "  y = BatchNormalization()(y)\n",
        "\n",
        "  y = Add()([y_shortcut, y])\n",
        "  y = LeakyReLU()(y)\n",
        "\n",
        "  return y\n",
        "\n",
        "\n",
        "def classifier(input_shape=[AUDIO_LENGTH, 1], num_classes=10):\n",
        "\n",
        "  X_input = Input(input_shape)\n",
        "  \n",
        "  y = Conv1D(128, kernel_size=3, strides=3, padding='same')(X_input)\n",
        "  y = add_Res1D(y, 3, 128)\n",
        "  y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "  y = add_Res1D(y, 3, 128)\n",
        "  y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "  #y = add_Res1D(y, 3, 256)\n",
        "  #y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "  #y = add_Res1D(y, 3, 256)\n",
        "  #y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "  #y = add_Res1D(y, 3, 256)\n",
        "  #y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "  #y = add_Res1D(y, 3, 256)\n",
        "  #y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "  #y = add_Res1D(y, 3, 256)\n",
        "  #y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "  #y = add_Res1D(y, 3, 256)\n",
        "  #y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "  #y = add_Res1D(y, 3, 512)\n",
        "  #y = MaxPooling1D(pool_size=3, strides=3)(y)\n",
        "  #y = Conv1D(512, kernel_size=1, strides=1, padding='same')(y)\n",
        "  y = Conv1D(256, kernel_size=1, strides=1, padding='same')(y)\n",
        "\n",
        "  model = Model(inputs = X_input, outputs = y)\n",
        "  return model"
      ],
      "metadata": {
        "id": "e8yYg2MnKF0w"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = classifier()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg8VBQB5zBgp",
        "outputId": "f2f55deb-e73c-4db8-a002-a80fc73f8e89"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_29 (InputLayer)          [(None, 110250, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1d_174 (Conv1D)            (None, 36750, 128)   512         ['input_29[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_175 (Conv1D)            (None, 36750, 128)   49280       ['conv1d_174[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 36750, 128)  512         ['conv1d_175[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " leaky_re_lu_118 (LeakyReLU)    (None, 36750, 128)   0           ['batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " conv1d_176 (Conv1D)            (None, 36750, 128)   49280       ['leaky_re_lu_118[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 36750, 128)  512         ['conv1d_176[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_60 (Add)                   (None, 36750, 128)   0           ['batch_normalization_131[0][0]',\n",
            "                                                                  'conv1d_174[0][0]']             \n",
            "                                                                                                  \n",
            " leaky_re_lu_119 (LeakyReLU)    (None, 36750, 128)   0           ['add_60[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_52 (MaxPooling1D  (None, 12250, 128)  0           ['leaky_re_lu_119[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_177 (Conv1D)            (None, 12250, 128)   49280       ['max_pooling1d_52[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 12250, 128)  512         ['conv1d_177[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " leaky_re_lu_120 (LeakyReLU)    (None, 12250, 128)   0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " conv1d_178 (Conv1D)            (None, 12250, 128)   49280       ['leaky_re_lu_120[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 12250, 128)  512         ['conv1d_178[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_61 (Add)                   (None, 12250, 128)   0           ['batch_normalization_133[0][0]',\n",
            "                                                                  'max_pooling1d_52[0][0]']       \n",
            "                                                                                                  \n",
            " leaky_re_lu_121 (LeakyReLU)    (None, 12250, 128)   0           ['add_61[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_53 (MaxPooling1D  (None, 4083, 128)   0           ['leaky_re_lu_121[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_179 (Conv1D)            (None, 4083, 256)    33024       ['max_pooling1d_53[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 232,704\n",
            "Trainable params: 231,680\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}